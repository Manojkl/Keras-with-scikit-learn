{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_scikitlearn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2fntQMBE+F3lI+dqgnf0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manojkl/Keras-with-scikit-learn/blob/master/keras_scikitlearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEpDUV57dc_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import requests"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yl3qo23qXNM",
        "colab_type": "text"
      },
      "source": [
        "Keras is a popular library for deep learning in Python. SImply define and build deep learning models.\n",
        "The scikit-learn library in Python is built upon the SciPy stack for efficient numerical computation.\n",
        "The Keras library provides a convenient wrapper for deep learning models to be used as classification or regression estimators in scikit-learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3--LTiRlH_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def telegram_bot_sendtext(bot_message):\n",
        "    \n",
        "    bot_token = ''\n",
        "    bot_chatID = ''\n",
        "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n",
        "\n",
        "    response = requests.get(send_text)\n",
        "\n",
        "    bot_token_alan = ''\n",
        "    bot_chatID_alan = ''\n",
        "    send_text_alan = 'https://api.telegram.org/bot' + bot_token_alan + '/sendMessage?chat_id=' + bot_chatID_alan + '&parse_mode=Markdown&text=' + bot_message\n",
        "\n",
        "    response = requests.get(send_text_alan) \n",
        "\n",
        "    return response.json()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKP2yp4glyNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keZva8LWdpby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "a4ef91a9-0910-4484-e674-8946ce49547b"
      },
      "source": [
        "data = np.loadtxt(\"data_banknote_authentication.txt\", delimiter=\",\")\n",
        "dataset = np.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "print(dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctn-ZENXdvR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b2833dfa-b589-4d6f-c073-9c557b0a76ab"
      },
      "source": [
        "# Functions to create model, required for Kerasclassifier\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim =4 ,activation = 'relu'))\n",
        "    model.add(Dense(4, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    #complete model\n",
        "    model.compile(loss =\"binary_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# fix random seed for reproducability\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "X_banknote = data[:,0:4]\n",
        "Y_banknote = data[:,4]\n",
        "print(X_banknote.shape)\n",
        "print(Y_banknote.shape)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "#create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs = 150, batch_size =10, verbose = 0)\n",
        "# evaluate using 10-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model,X_banknote,Y_banknote, cv =kfold)\n",
        "print(results.mean())\n",
        "result_for_banknote = \"The classification accuracy for 12 neurons in a single hidden layers banknote example: \"+ str(results.mean()) \n",
        "telegram_bot_sendtext(result_for_banknote) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1372, 4)\n",
            "(1372,)\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ok': True,\n",
              " 'result': {'chat': {'first_name': 'Alan',\n",
              "   'id': 1195073413,\n",
              "   'last_name': 'Gomez',\n",
              "   'type': 'private'},\n",
              "  'date': 1600093257,\n",
              "  'from': {'first_name': 'nlp_project',\n",
              "   'id': 1181840666,\n",
              "   'is_bot': True,\n",
              "   'username': 'nlp_alan_bot'},\n",
              "  'message_id': 81,\n",
              "  'text': 'The classification accuracy for 12 neurons in a single hidden layers banknote example: 1.0'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldy6eO3pkRx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8b62dd04-8b2d-4e56-bae6-150f32c6ee5e"
      },
      "source": [
        "# Functions to create model, required for Kerasclassifier\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim =8 ,activation = 'relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    #complete model\n",
        "    model.compile(loss =\"binary_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# fix random seed for reproducability\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "X_diabetes = dataset[:,0:8]\n",
        "Y_diabetes = dataset[:,8]\n",
        "print(X_diabetes.shape)\n",
        "print(Y_diabetes.shape)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "#create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs = 150, batch_size =10, verbose = 0)\n",
        "# evaluate using 10-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model,X_diabetes,Y_diabetes, cv =kfold)\n",
        "result_for_diabetes = \"The classification accuracy for 12 neurons in a single hidden layers diabetes example: \"+ str(results.mean())\n",
        "telegram_bot_sendtext(result_for_diabetes) \n",
        "print(results.mean())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8)\n",
            "(768,)\n",
            "0.7097744405269623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUJRI-tyrTxx",
        "colab_type": "text"
      },
      "source": [
        "Grid search deep learning model parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VqdapOZraY8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Kerasclassifier can take two arguments\n",
        "*   Grid search help us to evaluate our neural network model with different configuration and performance.\n",
        "*   We can have different optimization algorithms. \n",
        "*   Optimizers for searching different weight values.\n",
        "*   Initializers for preparing the network weights using different schemes.\n",
        "*   Epochs for training the model for a different number of exposures to the training dataset.\n",
        "*   Batches for varying the number of samples before a weight update.\n",
        "*   Each combination is then evaluated using the default of 3-fold stratified cross validation.\n",
        "*   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1wboqvtnOTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "404ffbd7-f647-4f69-d7ad-e8f0227d5837"
      },
      "source": [
        "def create_models(optimizer ='rmsprop', init = 'glorot_uniform'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12,input_dim=4,kernel_initializer=init,activation='relu'))\n",
        "  model.add(Dense(4,kernel_initializer=init,activation='relu'))\n",
        "  model.add(Dense(1,kernel_initializer=init,activation='sigmoid'))\n",
        "  #compile model\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "X_banknote = data[:,0:4]\n",
        "Y_banknote = data[:,4]\n",
        "# fix random seed for reproducability\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "model = KerasClassifier(build_fn=create_models, verbose = 0)\n",
        "# grid search, epochs, batch size and optimizer\n",
        "optimizer = ['rmsprop','adam']\n",
        "init = ['glorot_uniform','normal','uniform']\n",
        "epochs = [50,100,150]\n",
        "batches = [5,10,20]\n",
        "param_grid = dict(optimizer=optimizer,epochs = epochs, batch_size = batches, init=init)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_banknote,Y_banknote)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "best_banknote_result = \"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)\n",
        "telegram_bot_sendtext(best_banknote_result)\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    result = str(mean)+str(stdev)+\" with:\"+str(param)\n",
        "    telegram_bot_sendtext(result)  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 1.000000 using {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.999270 (0.001460) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.997818 (0.002909) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.998545 (0.002909) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.998545 (0.002909) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.999270 (0.001460) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.999270 (0.001460) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "1.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z44oiE-89Vhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b1b2d75-c471-49f4-c785-9253f5ccb0d1"
      },
      "source": [
        "def create_models(optimizer ='rmsprop', init = 'glorot_uniform'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12,input_dim=8,kernel_initializer=init,activation='relu'))\n",
        "  model.add(Dense(8,kernel_initializer=init,activation='relu'))\n",
        "  model.add(Dense(1,kernel_initializer=init,activation='sigmoid'))\n",
        "  #compile model\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "# X_banknote = dataset[:,0:8]\n",
        "# Y_banknote = dataset[:,8]\n",
        "# fix random seed for reproducability\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "model = KerasClassifier(build_fn=create_models, verbose = 0)\n",
        "# grid search, epochs, batch size and optimizer\n",
        "optimizer = ['rmsprop','adam']\n",
        "init = ['glorot_uniform','normal','uniform']\n",
        "epochs = [50,100,150]\n",
        "batches = [5,10,20]\n",
        "param_grid = dict(optimizer=optimizer,epochs = epochs, batch_size = batches, init=init)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_diabetes,Y_diabetes)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "best_diabetes_result = \"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)\n",
        "telegram_bot_sendtext(best_diabetes_result)\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    result = \"%f (%f) with: %r\" % (mean, stdev, param)\n",
        "    telegram_bot_sendtext(result)  \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.757907 using {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.664061 (0.062871) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.705814 (0.060262) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.714905 (0.025537) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.720041 (0.027660) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.726611 (0.034885) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.738392 (0.049493) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.684899 (0.027690) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.714931 (0.038969) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.748731 (0.046066) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.729225 (0.027812) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.734403 (0.039760) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.735769 (0.048339) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.725371 (0.049338) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.711035 (0.058203) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.734420 (0.019289) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.755284 (0.029230) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.727884 (0.040132) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.750038 (0.044828) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.681088 (0.056656) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.691554 (0.065787) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.712291 (0.038825) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.701910 (0.042556) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.688796 (0.011320) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.713607 (0.033686) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.685010 (0.057149) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.691503 (0.041036) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.747492 (0.035323) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.734428 (0.033887) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.723988 (0.032435) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.734394 (0.036346) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.683592 (0.039091) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.714922 (0.058633) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.747458 (0.029621) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.740947 (0.032519) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.748773 (0.025178) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.757907 (0.041306) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.701833 (0.033571) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.679773 (0.042303) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.686283 (0.035243) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.701910 (0.039218) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.701910 (0.027439) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.695450 (0.049201) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.692768 (0.028896) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.686258 (0.049153) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.740930 (0.033251) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.733155 (0.039368) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.717469 (0.018818) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.704524 (0.049818) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.722748 (0.050961) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "0.690255 (0.063920) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.742263 (0.041103) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "0.737043 (0.023512) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
            "0.756583 (0.030137) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "0.740939 (0.031311) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyiTV4tmCfHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}